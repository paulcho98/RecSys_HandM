{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082accfb-fee5-4440-87aa-2fbf65dde970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.datasets import AmazonBook\n",
    "from torch_geometric.nn import LightGCN\n",
    "from torch_geometric.utils import degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee888c5a-d60d-476f-9d3e-290026ab0697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>479507</td>\n",
       "      <td>232477</td>\n",
       "      <td>28866</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5328148</td>\n",
       "      <td>306128</td>\n",
       "      <td>7094</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4779175</td>\n",
       "      <td>41132</td>\n",
       "      <td>12896</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4852517</td>\n",
       "      <td>189305</td>\n",
       "      <td>34181</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7130496</td>\n",
       "      <td>238987</td>\n",
       "      <td>18606</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997367</th>\n",
       "      <td>500812</td>\n",
       "      <td>186580</td>\n",
       "      <td>26577</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997368</th>\n",
       "      <td>4897929</td>\n",
       "      <td>11831</td>\n",
       "      <td>1305</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997369</th>\n",
       "      <td>3916280</td>\n",
       "      <td>255785</td>\n",
       "      <td>1332</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997370</th>\n",
       "      <td>2789100</td>\n",
       "      <td>64400</td>\n",
       "      <td>16263</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997371</th>\n",
       "      <td>7004536</td>\n",
       "      <td>91322</td>\n",
       "      <td>25534</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6997372 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  customer_id  article_id  year  month  day\n",
       "0            479507       232477       28866    20      1   18\n",
       "1           5328148       306128        7094    20      6   18\n",
       "2           4779175        41132       12896    20      6    4\n",
       "3           4852517       189305       34181    20      6    6\n",
       "4           7130496       238987       18606    20      7   31\n",
       "...             ...          ...         ...   ...    ...  ...\n",
       "6997367      500812       186580       26577    20      1   19\n",
       "6997368     4897929        11831        1305    20      6    8\n",
       "6997369     3916280       255785        1332    20      5   14\n",
       "6997370     2789100        64400       16263    20      4    9\n",
       "6997371     7004536        91322       25534    20      7   28\n",
       "\n",
       "[6997372 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transactions = pd.read_csv(\"data/train.csv\")\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e41a8ce-0a1f-4fb8-b8c0-e5eb5d1a1e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[232477, 306128,  41132,  ..., 255785,  64400,  91322],\n",
       "        [ 28866,   7094,  12896,  ...,   1332,  16263,  25534]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# customers, articles = torch.LongTensor(transactions.customer_id), torch.LongTensor(transactions.article_id)\n",
    "# edge_index = torch.stack((torch.cat([customers, articles]), torch.cat([articles, customers])))\n",
    "# edge_index.shape\n",
    "edge_index = torch.LongTensor([transactions.customer_id, transactions.article_id])\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9edd63-2bb7-476e-9533-a9d9f964073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "data = HeteroData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560b9945-2dbf-4f2c-a569-998b8e6b784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['customer', 'purchases', 'article'].edge_index = edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a48510c-4720-43f5-91f6-5406164bf9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['article', 'purchased_by', 'customer'].edge_index = edge_index[[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c7cdb4-e157-4fd3-993c-c31c4340320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  (customer, purchases, article)={ edge_index=[2, 6997372] },\n",
      "  (article, purchased_by, customer)={ edge_index=[2, 6997372] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd98d24-687b-4e7a-b381-0425b7663ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[232477, 306128,  41132,  ..., 255785,  64400,  91322],\n",
      "        [ 28866,   7094,  12896,  ...,   1332,  16263,  25534]])\n",
      "tensor([[ 28866,   7094,  12896,  ...,   1332,  16263,  25534],\n",
      "        [232477, 306128,  41132,  ..., 255785,  64400,  91322]])\n"
     ]
    }
   ],
   "source": [
    "print(data['customer', 'purchases', 'article'].edge_index)\n",
    "print(data['article', 'purchased_by', 'customer'].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f8b338-537d-49a6-a65f-b0c701cd312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_customers = transactions.customer_id.nunique()\n",
    "num_articles = transactions.article_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e647f9f3-56a8-43f3-b162-51e534ec9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['customer'].num_nodes = num_customers\n",
    "data['article'].num_nodes = num_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec58956-3b02-4e0b-8c45-0d0b163fc05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  customer={ num_nodes=343166 },\n",
      "  article={ num_nodes=36806 },\n",
      "  (customer, purchases, article)={ edge_index=[2, 6997372] },\n",
      "  (article, purchased_by, customer)={ edge_index=[2, 6997372] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c16e4a64-ce7f-4ec5-99af-69e6a615c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb85812-9c2a-4f76-90e0-b55d7015081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 13994744], node_type=[379972], edge_type=[13994744])\n"
     ]
    }
   ],
   "source": [
    "data = data.to_homogeneous().to(device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c63437-ef47-455a-b641-5f2645cf1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "batch_size = 128\n",
    "mask = data.edge_index[0] < data.edge_index[1]\n",
    "train_edge_label_index = data.edge_index[:, mask]\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "train_loader = DataLoader(\n",
    "    range(train_edge_label_index.size(1)),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5894e9c7-9745-4b23-a134-56119ac64612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13994744])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[232477, 306128,  41132,  ..., 344498, 359429, 368700],\n",
       "        [372032, 350260, 356062,  ..., 255785,  64400,  91322]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.edge_index.shape)\n",
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8afbb92a-2d60-40a0-803e-ecc099e6d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6997372])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[232477, 306128,  41132,  ..., 255785,  64400,  91322],\n",
       "        [372032, 350260, 356062,  ..., 344498, 359429, 368700]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_edge_label_index.shape)\n",
    "train_edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5e05d5-34db-4c8e-9676-3093e699c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch_geometric.transforms as T\n",
    "# data = T.ToSparseTensor(data)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58b85bfc-d9be-4c1e-a62a-72d41c986404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "486e40ae-5719-4184-95c9-93a36fd85098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6997372, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d70d0c1d-8045-4ca5-84fc-c1148e7e5da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379972"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4695dafa-2b9e-4169-96b7-075f71e100c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(379971, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1c00cf0-8294-4f72-9ae5-47e8eb855c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightGCN(\n",
    "    num_nodes=data.num_nodes,\n",
    "    embedding_dim=32,\n",
    "    num_layers=2,\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52fc51f0-b259-49c4-b926-a2ff0b1d06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    total_loss = total_examples = 0\n",
    "\n",
    "    for index in tqdm(train_loader):\n",
    "        # Sample positive and negative labels.\n",
    "        pos_edge_label_index = train_edge_label_index[:, index]\n",
    "        print(f\"pos:{pos_edge_label_index.shape}\\n\", pos_edge_label_index)\n",
    "        neg_edge_label_index = torch.stack([\n",
    "            pos_edge_label_index[0],\n",
    "            torch.randint(num_customers, num_customers + num_articles,\n",
    "                          (index.numel(), ), device=device)\n",
    "        ], dim=0)\n",
    "        print(f\"neg:{neg_edge_label_index.shape}\\n\", neg_edge_label_index)\n",
    "        edge_label_index = torch.cat([\n",
    "            pos_edge_label_index,\n",
    "            neg_edge_label_index,\n",
    "        ], dim=1)\n",
    "        print(f\"edge: {edge_label_index.shape}\\n\", edge_label_index)\n",
    "        exit()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_rank, neg_rank = model(data.edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "        loss = model.recommendation_loss(\n",
    "            pos_rank,\n",
    "            neg_rank,\n",
    "            node_id=edge_label_index.unique(),\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * pos_rank.numel()\n",
    "        total_examples += pos_rank.numel()\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb2af511-c88a-4da1-b2cd-056c0de2b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(k: int):\n",
    "    emb = model.get_embedding(data.edge_index)\n",
    "    user_emb, book_emb = emb[:num_users], emb[num_users:]\n",
    "\n",
    "    precision = recall = total_examples = 0\n",
    "    for start in range(0, num_users, batch_size):\n",
    "        end = start + batch_size\n",
    "        logits = user_emb[start:end] @ book_emb.t()\n",
    "\n",
    "        # Exclude training edges:\n",
    "        mask = ((train_edge_label_index[0] >= start) &\n",
    "                (train_edge_label_index[0] < end))\n",
    "        logits[train_edge_label_index[0, mask] - start,\n",
    "               train_edge_label_index[1, mask] - num_users] = float('-inf')\n",
    "\n",
    "        # Computing precision and recall:\n",
    "        ground_truth = torch.zeros_like(logits, dtype=torch.bool)\n",
    "        mask = ((data.edge_label_index[0] >= start) &\n",
    "                (data.edge_label_index[0] < end))\n",
    "        ground_truth[data.edge_label_index[0, mask] - start,\n",
    "                     data.edge_label_index[1, mask] - num_users] = True\n",
    "        node_count = degree(data.edge_label_index[0, mask] - start,\n",
    "                            num_nodes=logits.size(0))\n",
    "\n",
    "        topk_index = logits.topk(k, dim=-1).indices\n",
    "        isin_mat = ground_truth.gather(1, topk_index)\n",
    "\n",
    "        precision += float((isin_mat.sum(dim=-1) / k).sum())\n",
    "        recall += float((isin_mat.sum(dim=-1) / node_count.clamp(1e-6)).sum())\n",
    "        total_examples += int((node_count > 0).sum())\n",
    "\n",
    "    return precision / total_examples, recall / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d967e623-cc18-4e46-9354-ad5b3b165d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/54667 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: tensor([[267578, 105122, 280048,  82298,  13651, 342911, 173934, 154147,  84566,\n",
      "         332007, 108656,  89341,   2133, 308653, 161498,  91863, 324956, 131229,\n",
      "         231066, 142844, 245581,  74492, 263755, 311800, 256827, 209071,  47845,\n",
      "         231042, 110262, 303504, 229259, 334767, 236353, 270880,  72797,  72169,\n",
      "         317684, 186707,  81299, 171684, 154825, 175758, 127207, 173379, 172259,\n",
      "         231141,  33509, 229027, 132632, 200426, 272027,  20397, 282246, 125405,\n",
      "         303762, 285029,  86414,  84751, 250071, 116366, 341140, 227483, 310501,\n",
      "         193842,  64260, 245230, 168037, 112871, 114231, 120177,  32958, 204531,\n",
      "         237212, 123252,  20935,  40078, 156825,  27175, 241362, 315223,  42059,\n",
      "         208452,  63959, 179433, 187568, 199556,  36593,  65350, 250067, 202184,\n",
      "         335741,  87259,  52969,  11920,  81852, 156151, 104906, 233301, 294754,\n",
      "           4920,  81928,  14321, 111019, 294306,  74899,  12469,   7868, 194470,\n",
      "         195294, 183993, 229171, 167742,  54678,  45818, 303922, 243105, 142923,\n",
      "         276337, 201983,   8130, 146716, 170790,  24570, 321478, 187846, 308037,\n",
      "          22726, 249031],\n",
      "        [361121, 378099, 366253, 354816, 357365, 376829, 368616, 344470, 374238,\n",
      "         351569, 364432, 372019, 350533, 376498, 376016, 377156, 360123, 369128,\n",
      "         374482, 349018, 343389, 378538, 353105, 357289, 375781, 357709, 356965,\n",
      "         362878, 371923, 361695, 351165, 352837, 364876, 365432, 358882, 375353,\n",
      "         344060, 365465, 344339, 356595, 363340, 353203, 358582, 372230, 355846,\n",
      "         362170, 365082, 360563, 379130, 353628, 374414, 353608, 377809, 354607,\n",
      "         353952, 356421, 360079, 356207, 360051, 362327, 348962, 363181, 370018,\n",
      "         350819, 373889, 370675, 346406, 377188, 367721, 349033, 374063, 345320,\n",
      "         353490, 367427, 363994, 362955, 359428, 356205, 360886, 347615, 368961,\n",
      "         367093, 361510, 363349, 349691, 378074, 350700, 366492, 355461, 350786,\n",
      "         347872, 366474, 356152, 347232, 371297, 369776, 376063, 343996, 368158,\n",
      "         348138, 370587, 376147, 346441, 373592, 372641, 350235, 363229, 354609,\n",
      "         362331, 360844, 347879, 358730, 344594, 372773, 376202, 368102, 346868,\n",
      "         360039, 369257, 355725, 361354, 359428, 345955, 373997, 378877, 365047,\n",
      "         356381, 346911]], device='cuda:0')\n",
      "neg: tensor([[267578, 105122, 280048,  82298,  13651, 342911, 173934, 154147,  84566,\n",
      "         332007, 108656,  89341,   2133, 308653, 161498,  91863, 324956, 131229,\n",
      "         231066, 142844, 245581,  74492, 263755, 311800, 256827, 209071,  47845,\n",
      "         231042, 110262, 303504, 229259, 334767, 236353, 270880,  72797,  72169,\n",
      "         317684, 186707,  81299, 171684, 154825, 175758, 127207, 173379, 172259,\n",
      "         231141,  33509, 229027, 132632, 200426, 272027,  20397, 282246, 125405,\n",
      "         303762, 285029,  86414,  84751, 250071, 116366, 341140, 227483, 310501,\n",
      "         193842,  64260, 245230, 168037, 112871, 114231, 120177,  32958, 204531,\n",
      "         237212, 123252,  20935,  40078, 156825,  27175, 241362, 315223,  42059,\n",
      "         208452,  63959, 179433, 187568, 199556,  36593,  65350, 250067, 202184,\n",
      "         335741,  87259,  52969,  11920,  81852, 156151, 104906, 233301, 294754,\n",
      "           4920,  81928,  14321, 111019, 294306,  74899,  12469,   7868, 194470,\n",
      "         195294, 183993, 229171, 167742,  54678,  45818, 303922, 243105, 142923,\n",
      "         276337, 201983,   8130, 146716, 170790,  24570, 321478, 187846, 308037,\n",
      "          22726, 249031],\n",
      "        [371351, 360188, 345816, 347696, 348238, 373506, 347313, 374281, 361451,\n",
      "         360429, 375328, 359732, 372364, 350806, 377291, 372023, 344344, 345971,\n",
      "         363726, 374744, 370198, 364082, 371095, 351053, 366597, 353259, 369561,\n",
      "         349062, 364662, 360006, 364963, 365211, 343282, 361292, 378070, 362896,\n",
      "         344698, 353425, 349503, 349043, 374504, 346392, 350566, 358922, 359279,\n",
      "         365025, 375744, 363993, 348029, 369282, 354126, 364706, 368684, 359054,\n",
      "         364352, 367695, 350130, 346458, 360354, 347170, 351703, 371809, 351333,\n",
      "         361770, 354806, 365671, 344731, 354679, 364543, 362308, 358873, 345431,\n",
      "         373682, 359153, 371373, 374655, 374108, 367012, 349790, 351937, 365890,\n",
      "         356708, 349751, 355293, 361732, 362062, 363782, 346312, 363288, 363136,\n",
      "         355314, 357906, 355544, 348367, 375136, 357581, 345877, 349812, 366412,\n",
      "         350276, 355130, 350406, 355682, 367812, 344818, 376387, 377076, 356224,\n",
      "         362298, 379317, 370165, 344738, 370250, 359308, 367998, 375770, 349574,\n",
      "         349412, 347447, 346874, 350494, 351147, 343882, 364314, 357037, 375533,\n",
      "         356792, 374665]], device='cuda:0')\n",
      "edge: tensor([[267578, 105122, 280048,  82298,  13651, 342911, 173934, 154147,  84566,\n",
      "         332007, 108656,  89341,   2133, 308653, 161498,  91863, 324956, 131229,\n",
      "         231066, 142844, 245581,  74492, 263755, 311800, 256827, 209071,  47845,\n",
      "         231042, 110262, 303504, 229259, 334767, 236353, 270880,  72797,  72169,\n",
      "         317684, 186707,  81299, 171684, 154825, 175758, 127207, 173379, 172259,\n",
      "         231141,  33509, 229027, 132632, 200426, 272027,  20397, 282246, 125405,\n",
      "         303762, 285029,  86414,  84751, 250071, 116366, 341140, 227483, 310501,\n",
      "         193842,  64260, 245230, 168037, 112871, 114231, 120177,  32958, 204531,\n",
      "         237212, 123252,  20935,  40078, 156825,  27175, 241362, 315223,  42059,\n",
      "         208452,  63959, 179433, 187568, 199556,  36593,  65350, 250067, 202184,\n",
      "         335741,  87259,  52969,  11920,  81852, 156151, 104906, 233301, 294754,\n",
      "           4920,  81928,  14321, 111019, 294306,  74899,  12469,   7868, 194470,\n",
      "         195294, 183993, 229171, 167742,  54678,  45818, 303922, 243105, 142923,\n",
      "         276337, 201983,   8130, 146716, 170790,  24570, 321478, 187846, 308037,\n",
      "          22726, 249031, 267578, 105122, 280048,  82298,  13651, 342911, 173934,\n",
      "         154147,  84566, 332007, 108656,  89341,   2133, 308653, 161498,  91863,\n",
      "         324956, 131229, 231066, 142844, 245581,  74492, 263755, 311800, 256827,\n",
      "         209071,  47845, 231042, 110262, 303504, 229259, 334767, 236353, 270880,\n",
      "          72797,  72169, 317684, 186707,  81299, 171684, 154825, 175758, 127207,\n",
      "         173379, 172259, 231141,  33509, 229027, 132632, 200426, 272027,  20397,\n",
      "         282246, 125405, 303762, 285029,  86414,  84751, 250071, 116366, 341140,\n",
      "         227483, 310501, 193842,  64260, 245230, 168037, 112871, 114231, 120177,\n",
      "          32958, 204531, 237212, 123252,  20935,  40078, 156825,  27175, 241362,\n",
      "         315223,  42059, 208452,  63959, 179433, 187568, 199556,  36593,  65350,\n",
      "         250067, 202184, 335741,  87259,  52969,  11920,  81852, 156151, 104906,\n",
      "         233301, 294754,   4920,  81928,  14321, 111019, 294306,  74899,  12469,\n",
      "           7868, 194470, 195294, 183993, 229171, 167742,  54678,  45818, 303922,\n",
      "         243105, 142923, 276337, 201983,   8130, 146716, 170790,  24570, 321478,\n",
      "         187846, 308037,  22726, 249031],\n",
      "        [361121, 378099, 366253, 354816, 357365, 376829, 368616, 344470, 374238,\n",
      "         351569, 364432, 372019, 350533, 376498, 376016, 377156, 360123, 369128,\n",
      "         374482, 349018, 343389, 378538, 353105, 357289, 375781, 357709, 356965,\n",
      "         362878, 371923, 361695, 351165, 352837, 364876, 365432, 358882, 375353,\n",
      "         344060, 365465, 344339, 356595, 363340, 353203, 358582, 372230, 355846,\n",
      "         362170, 365082, 360563, 379130, 353628, 374414, 353608, 377809, 354607,\n",
      "         353952, 356421, 360079, 356207, 360051, 362327, 348962, 363181, 370018,\n",
      "         350819, 373889, 370675, 346406, 377188, 367721, 349033, 374063, 345320,\n",
      "         353490, 367427, 363994, 362955, 359428, 356205, 360886, 347615, 368961,\n",
      "         367093, 361510, 363349, 349691, 378074, 350700, 366492, 355461, 350786,\n",
      "         347872, 366474, 356152, 347232, 371297, 369776, 376063, 343996, 368158,\n",
      "         348138, 370587, 376147, 346441, 373592, 372641, 350235, 363229, 354609,\n",
      "         362331, 360844, 347879, 358730, 344594, 372773, 376202, 368102, 346868,\n",
      "         360039, 369257, 355725, 361354, 359428, 345955, 373997, 378877, 365047,\n",
      "         356381, 346911, 371351, 360188, 345816, 347696, 348238, 373506, 347313,\n",
      "         374281, 361451, 360429, 375328, 359732, 372364, 350806, 377291, 372023,\n",
      "         344344, 345971, 363726, 374744, 370198, 364082, 371095, 351053, 366597,\n",
      "         353259, 369561, 349062, 364662, 360006, 364963, 365211, 343282, 361292,\n",
      "         378070, 362896, 344698, 353425, 349503, 349043, 374504, 346392, 350566,\n",
      "         358922, 359279, 365025, 375744, 363993, 348029, 369282, 354126, 364706,\n",
      "         368684, 359054, 364352, 367695, 350130, 346458, 360354, 347170, 351703,\n",
      "         371809, 351333, 361770, 354806, 365671, 344731, 354679, 364543, 362308,\n",
      "         358873, 345431, 373682, 359153, 371373, 374655, 374108, 367012, 349790,\n",
      "         351937, 365890, 356708, 349751, 355293, 361732, 362062, 363782, 346312,\n",
      "         363288, 363136, 355314, 357906, 355544, 348367, 375136, 357581, 345877,\n",
      "         349812, 366412, 350276, 355130, 350406, 355682, 367812, 344818, 376387,\n",
      "         377076, 356224, 362298, 379317, 370165, 344738, 370250, 359308, 367998,\n",
      "         375770, 349574, 349412, 347447, 346874, 350494, 351147, 343882, 364314,\n",
      "         357037, 375533, 356792, 374665]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 9.78 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 8.01 GiB memory in use. Of the allocated memory 6.06 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     precision, recall \u001b[38;5;241m=\u001b[39m test(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision@20: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall@20: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m quit()\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 22\u001b[0m pos_rank, neg_rank \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_label_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrecommendation_loss(\n\u001b[1;32m     25\u001b[0m     pos_rank,\n\u001b[1;32m     26\u001b[0m     neg_rank,\n\u001b[1;32m     27\u001b[0m     node_id\u001b[38;5;241m=\u001b[39medge_label_index\u001b[38;5;241m.\u001b[39munique(),\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch_geometric/nn/models/lightgcn.py:137\u001b[0m, in \u001b[0;36mLightGCN.forward\u001b[0;34m(self, edge_index, edge_label_index, edge_weight)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         edge_label_index \u001b[38;5;241m=\u001b[39m edge_index\n\u001b[0;32m--> 137\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m out_src \u001b[38;5;241m=\u001b[39m out[edge_label_index[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    140\u001b[0m out_dst \u001b[38;5;241m=\u001b[39m out[edge_label_index[\u001b[38;5;241m1\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch_geometric/nn/models/lightgcn.py:108\u001b[0m, in \u001b[0;36mLightGCN.get_embedding\u001b[0;34m(self, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    105\u001b[0m out \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m--> 108\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch_geometric/nn/conv/lg_conv.py:50\u001b[0m, in \u001b[0;36mLGConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     45\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m gcn_norm(edge_index, \u001b[38;5;28;01mNone\u001b[39;00m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim),\n\u001b[1;32m     46\u001b[0m                           add_self_loops\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, flow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow,\n\u001b[1;32m     47\u001b[0m                           dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                      \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:455\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    453\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 455\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:329\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, dim, data)\n\u001b[0;32m--> 329\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:276\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered an index error. Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got interval \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound negative indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.12/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:266\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacty of 9.78 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 8.01 GiB memory in use. Of the allocated memory 6.06 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    precision, recall = test(k=20)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Precision@20: '\n",
    "          f'{precision:.4f}, Recall@20: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fb1d4-3eba-4b10-b2bc-beecec8f3d6a",
   "metadata": {},
   "source": [
    "amazon = AmazonBook(\"./data\")\n",
    "amazon = amazon[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575a982-8429-4ec3-a9a4-ed7f3e2ad315",
   "metadata": {},
   "source": [
    "print(amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109adbc5-8885-4c02-bb63-047c4607efda",
   "metadata": {},
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf14bd-5ce1-4ce0-acba-65a9874c1e4f",
   "metadata": {},
   "source": [
    "2380730\n",
    "13994744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eca9cb-4edd-4edf-86ae-d2db9772dd68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
